import { Telegraf } from 'telegraf';
import { config } from 'dotenv';
import OpenAI from 'openai';
import express from 'express';

config();

const bot = new Telegraf(process.env.BOT_TOKEN);
const openai = new OpenAI({ apiKey: process.env.OPENAI_API_KEY });

// âœ… Commande /start
bot.start((ctx) => {
  ctx.reply("ðŸ‘‹ Salutâ€¯! Je suis un bot connectÃ© Ã  OpenAI. Pose-moi une question.");
});

// ðŸ“© RÃ©pond aux messages
bot.on('text', async (ctx) => {
  const userMessage = ctx.message.text;

  try {
    const completion = await openai.chat.completions.create({
      model: 'gpt-3.5-turbo',
      messages: [
        { role: 'system', content: "Tu es un assistant intelligent et amical." },
        { role: 'user', content: userMessage },
      ],
      max_tokens: 1000,
      temperature: 0.8,
    });

    const reply = completion.choices[0].message.content;
    ctx.reply(reply);
  } catch (error) {
    console.error("âŒ Erreur OpenAI :", error.response?.data || error.message);
    ctx.reply("âš ï¸ Une erreur est survenue avec OpenAI. " + (error.response?.data?.error?.message || error.message));
  }
});

// âœ… Lance le bot
bot.launch().then(() => {
  console.log("âœ… Le bot Telegram est lancÃ© !");
});

// âœ… Express pour Render
const app = express();
const port = process.env.PORT || 10000;

app.get("/", (req, res) => {
  res.send("âœ… Serveur en ligne.");
});

app.listen(port, () => {
  console.log(`âœ… Serveur lancÃ© sur le port ${port}`);
});

// ðŸ”š Interruption
process.once("SIGINT", () => bot.stop("SIGINT"));
process.once("SIGTERM", () => bot.stop("SIGTERM"));
